---
title: "Package Functions"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Package Functions}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: inline
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Installation

To install the package, please use: 

```
library(devtools)
install_github("doomlab/ViSe")
```

This installation will give you the latest version of the package, regardless of status on CRAN. 

```{r setup}
library(ViSe)
library(cowplot)
library(ggplot2)
```

## Example

To demonstrate the use of visual sensitivity analysis, we use a study of the effect of child maltreatment on the extent of mental health problems in terms of internalising and externalising behaviour. The study of Kisely and colleagues (2018) was based on a general population sample in Brisbane, Australia, and compared 3554 mother-child pairs without 'substantiated child maltreatment' to, for example, 73 pairs with child neglect. Note that the results vary across different types of maltreatment assessed, we choose child neglect because its results (a smaller but still considerable l after adjustment) are particularly suited to illustrating sensitivity analysis. Maltreatment was assessed 'by linkage to state child protection agency data'. Internalising and externalising behaviours were measured using the Youth Self-Report (YSR) scale at around the age of 21. The study reports unadjusted mean differences and mean differences adjusted for ‘gender, parental ethnicity, maternal age, family income, maternal relationship status, maternal education, youth income level, youth education level, youth marital status’ (e.g., likely based on ordinary least squares regression, but the paper does not specify that). To obtain the estimates and two-tailed 95% confidence intervals on the d scale, we used the `calculate_d` function. 

See supplemental document at https://static.cambridge.org/content/id/urn:cambridge.org:id:article:S0007125018002076/resource/name/S0007125018002076sup001.docx 

## Calculate effect size 

### Unadjusted scores

We can calculate the unadjusted scores from the supplemental material provided by the authors. 

```{r}
# internalising
internal_unadj <- 
  calculate_d(m1 = 14.37, # neglect mean
              sd1 = 10.716, # neglect sd
              n1 = 71, # neglect n
              m2 = 10.69, # none mean
              sd2 = 8.219, # none sd
              n2 = 3653, # none n
              a = .05, # alpha/confidence interval
              lower = TRUE) # lower or upper bound

internal_unadj$d # effect size 
internal_unadj$dlow # non-directional non-central lower 
internal_unadj$dlow_central # non-directional central lower 
internal_unadj$done_low # one-tailed non-central lower
internal_unadj$done_low_central # one-tailed central lower

# externalising
external_unadj <- 
  calculate_d(m1 = 13.14, sd1 = 8.066, n1 = 71, 
            m2 = 9.42, sd2 = 6.764, n2 = 3653, 
            a = .05, lower = TRUE)

external_unadj$d # effect size 
external_unadj$dlow # non-directional non-central lower 
external_unadj$dlow_central # non-directional central lower 
external_unadj$done_low # one-tailed non-central lower
external_unadj$done_low_central # one-tailed central lower
```

Note, you can also calculate directly from a t-test output in *R*, a *t*-value, or the dataframe of scores. 

### Adjusted scores

The adjusted scores are not displayed in raw score format, but rather mean difference scores. We can again use `calculate_d` in a different way:

```{r}
internal_adj <- 
  calculate_d(m1 = 2.73, # neglect mean
              sd1 = 10.716, # neglect sd
              n1 = 71, # neglect n
              m2 = 0, # none mean
              sd2 = 8.219, # none sd
              n2 = 3653, # none n
              a = .05, # alpha/confidence interval
              lower = TRUE) # lower or upper bound

internal_adj$d # effect size 
internal_adj$dlow # non-directional non-central lower 
internal_adj$dlow_central # non-directional central lower 
internal_adj$done_low # one-tailed non-central lower
internal_adj$done_low_central # one-tailed central lower

# externalising
m_diff <- 3.10
lower <- 1.49
# ci is m - t_alpha*SE = lower
SE <- (m_diff - lower)/qt(.025, # .05 / 2
                    df = (71+3653 - 2), # n - 1 + n - 1
                    lower.tail = FALSE) 
SE

# confirm correct
# p value is listed as < .001
pt(q = m_diff / SE, # t value
   df = (71+3653 - 2), # df 
   lower.tail = FALSE)*2 # upper tail * 2 for two tails 

external_adj <- 
  calculate_d(t = m_diff/SE, # t-score
            n1 = 71, # neglect n
            n2 = 3653, # none n
            a = .05,  # alpha/confidence interval
            lower = TRUE) # lower or upper bound

external_adj$d # effect size 
external_adj$dlow # non-directional non-central lower 
external_adj$dlow_central # non-directional central lower 
external_adj$done_low # one-tailed non-central lower
external_adj$done_low_central # one-tailed central lower
```

## Visualisation of c

Given these statistics, we can use `visualize_c` to visualize the combinations of effect size and correlation that would support an effect. 

```{r}
plots_1 <- visualize_c(dlow = internal_unadj$dlow_central)$graph + 
  ggtitle("Internal Unadjusted") + 
  annotate("text", label = paste0("l = ", round(internal_unadj$dlow_central, 2)), 
           x = -1.5, y = -.5)
plots_2 <- visualize_c(dlow = external_unadj$dlow_central)$graph + 
  ggtitle("External Unadjusted") + 
  annotate("text", label = paste0("l = ", round(external_unadj$dlow_central, 2)), 
           x = -1.5, y = -.5)
plots_3 <- visualize_c(dlow = internal_adj$dlow_central)$graph + 
  ggtitle("Internal Adjusted") + 
    annotate("text", label = paste0("l = ", round(internal_adj$dlow_central, 2)), 
           x = -1.5, y = -.5)
plots_4 <- visualize_c(dlow = external_adj$dlow_central)$graph + 
  ggtitle("External Adjusted") + 
  annotate("text", label = paste0("l = ", round(external_adj$dlow_central, 2)), 
         x = -1.5, y = -.5)

plot_grid(plots_1, plots_2, 
          plots_3, plots_4, 
          nrow = 2)

ggsave(filename = "visualize_c.png")
```

## Calculation of adjusted values

If you have information about regression coefficients, you can use this function to calculate the adjusted coefficient. Include $\beta_{xz}$, $\beta_{uxz}$, and $d$ to calculate the adjusted coefficient. 

```{r}
adjusted_coef(effect_xz = .2, # effect of x and z
    effect_uxz = .4, # effect of x, u, and z
    effect_d = .12) # effect size of difference score between groups 
```

## Visualization of d and r

If you don't have a clue what to explect, you can create some visualizations of *d* and or *r* to help determine the overlap between groups. You can create graphs with just the effect size or create a graph by entering some numbers you might expect for your study. This graph will help you visualize how much overlap two distributions have at various effect sizes. 

```{r}
visual_d <- 
  estimate_d(m1 = 14.37, # neglect mean
          sd1 = 10.716, # neglect sd
          n1 = 71, # neglect n
          m2 = 10.69, # none mean
          sd2 = 8.219, # none sd
          n2 = 3653) # none n

visual_d$d

visual_d$graph

ggsave(filename = "estimate_d.png")

estimate_d(d = .25)$graph
```

```{r}
visual_r <- 
  estimate_r(r = .3)

visual_r$graph

ggsave(filename = "estimate_r.png")
```

## Calculation between effect sizes and other numbers

You can also switch between various effect sizes for your favorite effect size. In each, you only have to enter the *d* value. 

1) d_to_f2: Cohen’s f and f2 
2) d_to_nnt: Number needed to treat 
3) d_to_r: correlation coefficient 
4) probability_superiority: The probability of superiority  
5) proportion_overlap: u1 represents the proportion of non-overlap across both group distributions, u2 indicates the proportion that one group is more than the same proportion in the other group, u3 shows the proportion of one group that is smaller than the median of the other group, and p_o is the proportional overlap of groups. 

```{r}
d_to_f2(d = .25)
d_to_nnt(d = .25)
d_to_r(d = .25)
probability_superiority(d = .25)
proportion_overlap(d = .25)
```

## Visualization of effect sizes

Using the conversion factors above, you can also make a graph of all the possible versions of effect sizes grouped together. 

```{r}
visualize_effects(d = .5)$graph
ggsave(filename = "visualize_effects.png")
```

## Combining it all together

You can then use the two estimation functions to create a graph that shows you which combinations of *d* and *r* would be included in the possible effects.

```{r}
visual_c_mapped <- 
  visualize_c_map(dlow = .25,
                  dvalues = c(.2, .3, .8),
                  rvalues = c(.1, .4, .3))

visual_c_mapped$graph
```
